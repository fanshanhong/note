


方法

channel与pipeline关系    网络到socket到channel再到pipeline处理



数据从网络到socket。 socket 是TCP/IP的抽象层。

然后再从socket传递到channle。

channel 就理解为： 是对于socket的连接点。

数据到了channel之后，就会进入到与channel 关联的那个pipline。pipiline 是个容器， 里面有一组handler， 对来自网络的数据进行处理。





**<u>pipeline创建时机 创建channel的时候一起创建的</u>**



abstructChannel 的 构造里面， newChannelPipline的。

```java
    /**
     * Creates a new instance.
     *
     * @param parent
     *        the parent of this channel. {@code null} if there's no parent.
     */
    protected AbstractChannel(Channel parent) {
        this.parent = parent;
        id = newId();
        unsafe = newUnsafe();
        pipeline = newChannelPipeline();
    }
```



pipeline里面有个head  有个tail，干嘛的。







pipeline文档，过滤器   拦截器

文档多，但是很好理解，关键在于是不是看了。

```java
/**
 * A list of {@link ChannelHandler}s which handles or intercepts inbound events and outbound operations of a
 * {@link Channel}.  {@link ChannelPipeline} implements an advanced form of the
 * <a href="http://www.oracle.com/technetwork/java/interceptingfilter-142169.html">Intercepting Filter</a> pattern
 * to give a user full control over how an event is handled and how the {@link ChannelHandler}s in a pipeline
 * interact with each other.
 
 ChannelPipeline是 ChannelHandler的列表（容器），这些ChannelHandler会处理或者拦截入站的事件和出站的操作。
 ChannelPipeline 是一种高级过滤器模式的实现，目的是：让用户可以完全控制事件的处理方式以及管道中的{@link ChannelHandler}如何彼此交互。
 
 *
 * <h3>Creation of a pipeline</h3> 创建一个Pipeline
 *
 * Each channel has its own pipeline and it is created automatically when a new channel is created.
 每个channel都有属于自己的pipeline，并且这个pipeline是在channel被创建的时候自动被创建的，并且建立好与channel的关联关系。
 我的理解：pipeline就是藏在channel背后的容器，当有数据从socket到达channel字后， 就全部转交给这个容器里面的handler去处理
 *
 * <h3>How an event flows in a pipeline</h3> 事件在pipeline中是如何流动的
 *
 * The following diagram describes how I/O events are processed by {@link ChannelHandler}s in a {@link ChannelPipeline}
 * typically. An I/O event is handled by either a {@link ChannelInboundHandler} or a {@link ChannelOutboundHandler}
 * and be forwarded to its closest handler by calling the event propagation methods defined in
 * {@link ChannelHandlerContext}, such as {@link ChannelHandlerContext#fireChannelRead(Object)} and
 * {@link ChannelHandlerContext#write(Object)}.
 下面的这个图， 描述了一个IO事件是如何被pieline中 的 handler 处理的。
个人理解：pipeline是个容器，里面有很多handler，具体事件全是handler来处理的！
一个事件要么被入站处理器处理，要么被出站处理器处理。一个处理器处理完了之后，就会调用定义在ChannelHandlerContext中的事件传播方法（fireChannelRead）将事件转发给与它最近的handler去处理。
 
 *
 * <pre>
 *                                                 I/O Request
 *                                            via {@link Channel} or
 *                                        {@link ChannelHandlerContext}
 *                                                      |
 *  +---------------------------------------------------+---------------+
 *  |                           ChannelPipeline         |               |
 *  |                                                  \|/              |
 *  |    +---------------------+            +-----------+----------+    |
 *  |    | Inbound Handler  N  |            | Outbound Handler  1  |    |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |              /|\                                  |               |
 *  |               |                                  \|/              |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |    | Inbound Handler N-1 |            | Outbound Handler  2  |    |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |              /|\                                  .               |
 *  |               .                                   .               |
 *  | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|
 *  |        [ method call]                       [method call]         |
 *  |               .                                   .               |
 *  |               .                                  \|/              |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |    | Inbound Handler  2  |            | Outbound Handler M-1 |    |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |              /|\                                  |               |
 *  |               |                                  \|/              |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |    | Inbound Handler  1  |            | Outbound Handler  M  |    |
 *  |    +----------+----------+            +-----------+----------+    |
 *  |              /|\                                  |               |
 *  +---------------+-----------------------------------+---------------+
 *                  |                                  \|/
 *  +---------------+-----------------------------------+---------------+
 *  |               |                                   |               |
 *  |       [ Socket.read() ]                    [ Socket.write() ]     |
 *  |                                                                   |
 *  |  Netty Internal I/O Threads (Transport Implementation)            |
 *  +-------------------------------------------------------------------+
 
 左侧是入站序列，右侧是出站序列。相互独立。
 
 * </pre>
 * An inbound event is handled by the inbound handlers in the bottom-up direction as shown on the left side of the
 * diagram.  An inbound handler usually handles the inbound data generated by the I/O thread on the bottom of the
 * diagram.  The inbound data is often read from a remote peer via the actual input operation such as
 * {@link SocketChannel#read(ByteBuffer)}.  If an inbound event goes beyond the top inbound handler, it is discarded
 * silently, or logged if it needs your attention.
 如图左侧所示，一个入站事件由入站处理程序按自下而上的方向进行处理。
 通常情况下，一个入站处理器 处理 I / O线程生成的入站数据（如图底部所画的）。
 这个入站数据通常都是通过实际的输入操作（例如* {@link SocketChannel＃read（ByteBuffer）}）从远程对等方读取的。
 如果入站事件超出了顶部入站处理程序的范围，则它会被悄悄地丢弃了，或者如果你需要的话也可以记录下来。
 比如，一个入站的事件（数据）流动到了pipeline中的最后一个Handler， 你不处理它的话， 就自动把它给丢弃了，不管了。
 
 * <p>
 * An outbound event is handled by the outbound handler in the top-down direction as shown on the right side of the
 * diagram.  An outbound handler usually generates or transforms the outbound traffic such as write requests.
 * If an outbound event goes beyond the bottom outbound handler, it is handled by an I/O thread associated with the
 * {@link Channel}. The I/O thread often performs the actual output operation such as
 * {@link SocketChannel#write(ByteBuffer)}.
 出站事件 是 被出站处理器 按照自顶向下的顺序处理的，如图右侧所示。
 一个出站处理器通常会产生或者传输出站数据。
 产生： 比如，你产生一个ByteBuf 写到网络中。
 传输： 比如，你把一个类型转成另外一个类型，然后向后一个出站处理器传输。
 如果一个出站的事件超过了最下面的这个出站处理器（上图所示的Handler M处理完成），则由与* {@link Channel}关联的I / O线程处理。I / O线程通常执行实际的输出操作，例如 SocketChannel.write（ByteBuffer），就是把数据写到网络中。
 * <p>
 * For example, let us assume that we created the following pipeline:
 举个栗子，我们床架了如下的pipeline
 * <pre>
 * {@link ChannelPipeline} p = ...;
 * p.addLast("1", new InboundHandlerA());//
 * p.addLast("2", new InboundHandlerB());
 * p.addLast("3", new OutboundHandlerA());
 * p.addLast("4", new OutboundHandlerB());
 * p.addLast("5", new InboundOutboundHandlerX());
 
 画个图，表示一下上面的情况
 
 一个pipeline，从头到尾，如下。
 inA  -   inB  -  outA  -  outB   in-out-X 
 入站，从头开始
 出站，从尾开始
 
 * </pre>
 * In the example above, the class whose name starts with {@code Inbound} means it is an inbound handler.
 * The class whose name starts with {@code Outbound} means it is a outbound handler.
 上面这个栗子，以Inbound开头的类是入站处理器。 以Outbound开头的类表示 一个出站处理器。
 * <p>
 * In the given example configuration, the handler evaluation order is 1, 2, 3, 4, 5 when an event goes inbound.
 * When an event goes outbound, the order is 5, 4, 3, 2, 1.  On top of this principle, {@link ChannelPipeline} skips
 * the evaluation of certain handlers to shorten the stack depth:
 在给定的这个栗子的配置中，事件进入时，处理程序评估顺序为1、2、3、4、5。 *当事件出站时，顺序为5、4、3、2、1。
 * <ul>
 * <li>3 and 4 don't implement {@link ChannelInboundHandler}, and therefore the actual evaluation order of an inbound
 *     event will be: 1, 2, and 5.</li>
  3  4  没有实现ChannelInboundHandler， 因此，对于入站，真正的处理顺序是： 125
 * <li>1 and 2 don't implement {@link ChannelOutboundHandler}, and therefore the actual evaluation order of a
 *     outbound event will be: 5, 4, and 3.</li>
 12 没有实现ChannelOutboundHandler，因此对于出站，真正的处理吮吸是  5 4 3 
 * <li>If 5 implements both {@link ChannelInboundHandler} and {@link ChannelOutboundHandler}, the evaluation order of
 *     an inbound and a outbound event could be 125 and 543 respectively.</li>
 因为5 即实现了ChannelInboundHandler 也实现了ChannelOutboundHandler，因此，入站和出站的顺序分别为  125和543
 * </ul>
 *
 * <h3>Forwarding an event to the next handler</h3>将事件转发到下一个处理程序
 *
 * As you might noticed in the diagram shows, a handler has to invoke the event propagation methods in
 * {@link ChannelHandlerContext} to forward an event to its next handler.  Those methods include:
 一个处理器必须调用事件传播方法（定义在ChannelHandlerContext里面的）把事件发送到下一个处理器。
 * <ul>
 * <li>Inbound event propagation methods:
 入站事件传播方法：
 *     <ul>
 *     <li>{@link ChannelHandlerContext#fireChannelRegistered()}</li>
 *     <li>{@link ChannelHandlerContext#fireChannelActive()}</li>
 *     <li>{@link ChannelHandlerContext#fireChannelRead(Object)}</li>
 *     <li>{@link ChannelHandlerContext#fireChannelReadComplete()}</li>
 *     <li>{@link ChannelHandlerContext#fireExceptionCaught(Throwable)}</li>
 *     <li>{@link ChannelHandlerContext#fireUserEventTriggered(Object)}</li>
 *     <li>{@link ChannelHandlerContext#fireChannelWritabilityChanged()}</li>
 *     <li>{@link ChannelHandlerContext#fireChannelInactive()}</li>
 *     <li>{@link ChannelHandlerContext#fireChannelUnregistered()}</li>
 *     </ul>
 * </li>
 * <li>Outbound event propagation methods:
 出站事件传播方法：
 *     <ul>
 *     <li>{@link ChannelHandlerContext#bind(SocketAddress, ChannelPromise)}</li>
 *     <li>{@link ChannelHandlerContext#connect(SocketAddress, SocketAddress, ChannelPromise)}</li>
 *     <li>{@link ChannelHandlerContext#write(Object, ChannelPromise)}</li>
 *     <li>{@link ChannelHandlerContext#flush()}</li>
 *     <li>{@link ChannelHandlerContext#read()}</li>
 *     <li>{@link ChannelHandlerContext#disconnect(ChannelPromise)}</li>
 *     <li>{@link ChannelHandlerContext#close(ChannelPromise)}</li>
 *     <li>{@link ChannelHandlerContext#deregister(ChannelPromise)}</li>
 *     </ul>
 * </li>
 * </ul>
 *
 * and the following example shows how the event propagation is usually done:
 下面这个栗子展示了事件传播是如何完成的额：
 *
 * <pre>
 * public class MyInboundHandler extends {@link ChannelInboundHandlerAdapter} {
 *     {@code @Override}
 *     public void channelActive({@link ChannelHandlerContext} ctx) {
 *         System.out.println("Connected!");
 					 // 打印后，丢给下一个处理器。其实是调用下一个处理器的channelActive 方法
 *         ctx.fireChannelActive();
 *     }
 * }
 *
 * public class MyOutboundHandler extends {@link ChannelOutboundHandlerAdapter} {
 *     {@code @Override}
 *     public void close({@link ChannelHandlerContext} ctx, {@link ChannelPromise} promise) {
 *         System.out.println("Closing ..");
 					 // 丢给下一个处理器处理，其实是调用下一个处理器的close方法吧
 *         ctx.close(promise);
 *     }
 * }
 * </pre>
 *
 * <h3>Building a pipeline</h3>建立管道
 * <p>
 * A user is supposed to have one or more {@link ChannelHandler}s in a pipeline to receive I/O events (e.g. read) and
 * to request I/O operations (e.g. write and close).  For example, a typical server will have the following handlers
 * in each channel's pipeline, but your mileage may vary depending on the complexity and characteristics of the
 * protocol and business logic:
 用户想要在一个pipeline中具有一个或多个{@link ChannelHandler}来接收I / O事件（例如，读取）和*以请求I / O操作（例如，写入和关闭）。
 例如，典型的服务器在每个通道的管道中将具有以下处理程序，但是您的里程可能会根据协议和业务逻辑的复杂性和特征而有所不同：
 *
 * <ol>
 * <li>Protocol Decoder - translates binary data (e.g. {@link ByteBuf}) into a Java object.</li>
 协议解码器
 * <li>Protocol Encoder - translates a Java object into binary data.</li>
 协议编码器
 * <li>Business Logic Handler - performs the actual business logic (e.g. database access).</li>
 业务逻辑处理器
 * </ol>
 *
 * and it could be represented as shown in the following example:
 *
 * <pre>
 * static final {@link EventExecutorGroup} group = new {@link DefaultEventExecutorGroup}(16);
 * ...
 *
 * {@link ChannelPipeline} pipeline = ch.pipeline();
 *
 * pipeline.addLast("decoder", new MyProtocolDecoder());
 * pipeline.addLast("encoder", new MyProtocolEncoder());
 *
 * // Tell the pipeline to run MyBusinessLogicHandler's event handler methods
 * // in a different thread than an I/O thread so that the I/O thread is not blocked by
 * // a time-consuming task.
 * // If your business logic is fully asynchronous or finished very quickly, you don't
 * // need to specify a group.
 * pipeline.addLast(group, "handler", new MyBusinessLogicHandler());
 
 // 注意这个重载的方法， 这是告诉pipeline 去执行MyBusinessLogicHandler里面的方法的时候，是在一个新的线程，而不是在IO线程，这样IO线程就不会因为耗时任务被阻塞了。
 如果你的业务逻辑是完全异步的，或者非常快，那么你就不需要单独指定一个  group了
 
 或者， 我们也可以在MyBusinessLogicHandler 里面自己开一个线程池去处理我们的业务逻辑。
 Netty给我们提供的方式是addLast的时候指定一个group
 * </pre>
 *
 * <h3>Thread safety</h3> 线程安全
 * <p>
 * A {@link ChannelHandler} can be added or removed at any time because a {@link ChannelPipeline} is thread safe.
 * For example, you can insert an encryption handler when sensitive information is about to be exchanged, and remove it
 * after the exchange.
 ChannelHandler 可以在任何时候被添加或者删除因为 ChannelPipeline 是线程安全的。 
 */
public interface ChannelPipeline
        extends ChannelInboundInvoker, ChannelOutboundInvoker, Iterable<Entry<String, ChannelHandler>> {}
```



对于一个普通的过滤器/拦截器，比如serverlet， 在请求到达目标组件之前，会按顺序经过过滤器。到达目标组件之后，目标组件处理完成之后，会沿着相反的顺序经过过滤器，然后回到客户端。

也就是说，  普通的过滤器/拦截器，既处理请求，也处理响应。无法分开。入（请求）和出（响应），都必须经过这个过滤器。

需求，比如有123 一共3个过滤器，想要 入（请求）时候经过  1  2  ，不经过3就到达服务器。 返回的时候，只经过3，然后直接给到客户端。原有的方式无法实现这种  请求和响应分开处理的情况。
高级  就是入站和出站分开了。入站处理器专门处理入站的，出专门处理出的，相对独立。

每个channel都拥有自己的pipeline
在channel的构造里面会创建出来。

pipeline是个容器，里面有很多handler，事件去由handler来处理的

一个handler处理完了，就丢给与它与接近的下一个handler。是通过调用事件传播方法来丢的
注意看一下addlast重载方法







HeadContext  TailContext